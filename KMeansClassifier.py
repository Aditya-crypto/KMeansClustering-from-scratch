# -*- coding: utf-8 -*-
"""A2q6.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1onqrYwQUrdIe968PFAG6VQwq3IFZWpFc
"""

import pandas as pd
import numpy as np
import re
import string
from sklearn.model_selection import train_test_split
from sklearn import svm
import sys
import glob
import errno
import ntpath
from sklearn.feature_extraction.text import TfidfVectorizer
import copy
import random

class Cluster:
    x_train=None
    y_train=None
    test=None
    
    def clean_text(self,text):
      text=text.lower()
      text=re.sub('\[.*"\']','',text)
      text=text.replace("\n",' ')
      text=re.sub('[%s]' % re.escape(string.punctuation),'',text)
      return text

    def cluster(self,path):
      df=[]
      path = path+'*.txt'   
      files = glob.glob(path)   
      for name in files:
        with open(name,'rb') as f:
          temp=[]
          temp.append(f.read())
          filename=ntpath.basename(name)
          temp.append(filename)
          df.append(temp)
      df = pd.DataFrame(df, columns = ['text', 'filename'])
      round1= lambda x: self.clean_text(str(x))
      actual_files=df.filename
      # print(actual_labels)
      clean_data=pd.DataFrame(df.text.apply(round1))
      # print(clean_data)
      cv1=TfidfVectorizer(stop_words='english')
      data_cv1=cv1.fit_transform(clean_data.text)
      pp_df1=pd.DataFrame(data_cv1.toarray(),columns=cv1.get_feature_names())
      pp_df1=np.array(pp_df1)
      n,c=pp_df1.shape
      rsam=[[]]*5
      for i in range(0,5):
        rsam[i]=pp_df1[random.randrange(0,n)]
      error=1
      while(error>0.01):
        predlist=[]
        new_list=[]
        for i in pp_df1[:,:]:
          result=[]
          index=0
          for j in rsam:
            eudist=0.0
            val=np.linalg.norm(i-j)
            result.append((val,index+1))
            index+=1
          # print(result)
          # print(min(result))
          res=min(result)
          predlist.append(res)
          new_list.append(res[1])
        print(predlist)
        mp1=[[0]*c]*5
        count=[0]*5
        s=pp_df1
        # print(X_train.shape)
        for k in range(0,len(predlist)):
          mp1[predlist[k][1]-1]+=s[k]
          count[predlist[k][1]-1]+=1
        for i in range(0,5):
          mp1[i]/=count[i]
        error=0
        mp1=np.array(mp1)
        for o in range(0,5):
          error=error+np.linalg.norm(mp1[o]-rsam[o])
        rsam=copy.deepcopy(mp1)
        # print(error)
      return dict(zip(actual_files, new_list))